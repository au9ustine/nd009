{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity nd009\n",
    "\n",
    "## Install Udacity\n",
    "\n",
    "* pip + virtualenv\n",
    "  ```\n",
    "  $ virtualenv --python=python2 env\n",
    "  $ source env/bin/activate\n",
    "  $ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0rc2-py2-none-any.whl\n",
    "  $ pip install -U $TF_BINARY_URL\n",
    "  $ pip install -U 'ipython[notebook]'\n",
    "  $ pip install scikit-learn pyreadline Pillow matplotlib scipy\n",
    "  ```\n",
    "\n",
    "* docker\n",
    "  ```\n",
    "  $ docker pull gcr.io/tensorflow/tensorflow\n",
    "  $ git clone git@github.com:tensorflow/tensorflow.git\n",
    "  $ cp tensorflow/tensorflow/examples/udacity/*.ipynb ./\n",
    "  $ cp tensorflow/tensorflow/examples/udacity/Dockerfile ./\n",
    "  $ docker build -t nd009 .\n",
    "  ```\n",
    "\n",
    "## Get data\n",
    "\n",
    "on macOS, for example\n",
    "```\n",
    "$ wget -c http://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz\n",
    "$ shasum notMNIST_large.tar.gz\n",
    "  342702831f08438e1fc830ca0f016ec7bc5ab2e8  notMNIST_large.tar.gz\n",
    "$ wget -c http://commondatastorage.googleapis.com/books1000/notMNIST_small.tar.gz\n",
    "$ shasum notMNIST_small.tar.gz\n",
    "  23db76a71f83982f18a51b855b5746bd52e01f1c  notMNIST_small.tar.gz\n",
    "```\n",
    "\n",
    "## Run\n",
    "\n",
    "* ipython notebook\n",
    "  ```\n",
    "  $ ipython notebook\n",
    "  ```\n",
    "\n",
    "* docker\n",
    "  ```\n",
    "  $ docker run -it --name tensorflow-udaicty --rm -p 8888:8888 -v `pwd`:/notebooks nd009\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "\n",
    "### Supervised Classification\n",
    "\n",
    "### One-Hot Encoding\n",
    "\n",
    "### Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Classification\n",
    "\n",
    "`wx+b` (Linear Model) -> `y` (Logit) -> `S(y)` (softmax) -> `D(S,L)` (Cross-Entropy) -> `L` (1-Hot Labels)\n",
    "\n",
    "Loss = Average Cross-Entropy\n",
    "\n",
    "$$\\mathscr{L} = \\frac{1}{N}\\sum_i D(S(\\omega x_i+b),L_i)$$\n",
    "\n",
    "$w$ is **Big Matrix**, $\\sum$ is **Big Sum**\n",
    "\n",
    "Turn machine learning problem into numerical optimization probelm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Inputs and Initial Weights\n",
    "\n",
    "* variables zero mean ($X_i = 0$) and euqal variance whenever possible ($\\sigma(X_i) = \\sigma(X_j)$)\n",
    "* A large $\\sigma$ means that your distribution will have large peaks, while small $\\sigma$ means uncertain\n",
    "\n",
    "For initialization of the Logistic Classifier\n",
    "\n",
    "$$ \\mathscr{L} = \\frac{1}{N}\\sum_i D(S(\\omega X_i + b), L_i) $$\n",
    "\n",
    "The factors would be\n",
    "* $\\sigma \\rightarrow \\omega$\n",
    "* $\\frac{pixels-128}{128} \\rightarrow X_i$\n",
    "* $\\phi \\rightarrow b$\n",
    "\n",
    "Optimization\n",
    "\n",
    "* $\\omega \\leftarrow \\omega - \\alpha \\Delta_{\\omega}\\mathscr{L}$\n",
    "* $b \\leftarrow b - \\alpha \\Delta_{b}\\mathscr{L}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Performance\n",
    "\n",
    "* Training\n",
    "* Validation\n",
    "* Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higgs Boson Machine Learning Challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Size\n",
    "\n",
    "* Rule of '30'\n",
    "  \n",
    "  $80\\% \\rightarrow 81\\%$, which $\\Delta$ is $1\\%$, and $\\frac{1 \\times 3000}{100} = 30$\n",
    "  \n",
    "* It would be better to have \n",
    "  * validation set size $\\gt 30000$ examples\n",
    "  * changes $\\gt 0.1\\%$ in accurracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (S.G.D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Tuning\n",
    "\n",
    "* ~~Initial Learning Rate~~\n",
    "* ~~Learning Rate Decay~~\n",
    "* ~~Momentum~~\n",
    "* Batch Size\n",
    "* Weight Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `notMNIST`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [TensorFlow Installation](https://www.tensorflow.org/versions/master/get_started/os_setup.html)\n",
    "* [notMNIST Datasets](http://yaroslavvb.blogspot.co.uk/2011/09/notmnist-dataset.html)\n",
    "* [Udacity Docker on TensorFlow Installation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
